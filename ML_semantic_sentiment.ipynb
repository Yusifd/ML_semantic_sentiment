{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MPex_p524Xd"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "\n",
        "model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "\n",
        "\n",
        "sentences = [\n",
        "    \"Bu g√ºn universitetd…ô s√ºni intellekt m√∂vzusunda seminar ke√ßirildi.\",\n",
        "    \"Yeni t…ôdris platformasƒ± t…ôl…ôb…ôl…ôr √º√ß√ºn istifad…ôy…ô verildi.\",\n",
        "    \"ƒ∞nformasiya t…ôhl√ºk…ôsizliyi m√∂vzusunda t…ôlim t…ô≈ükil olundu.\",\n",
        "    \"Magistratura √ºzr…ô q…ôbul qaydalarƒ± yenil…ôndi.\",\n",
        "    \"T…ôl…ôb…ôl…ôrin startap layih…ôl…ôri √º√ß√ºn yeni fond yaradƒ±ldƒ±.\",\n",
        "    \"Universitet m√º…ôlliml…ôri √º√ß√ºn r…ôq…ômsal bacarƒ±qlar t…ôlimi ke√ßirildi.\",\n",
        "    \"Yeni ara≈üdƒ±rma m…ôrk…ôzind…ô robototexnika laboratoriyasƒ± a√ßƒ±ldƒ±.\"\n",
        "]\n",
        "\n",
        "\n",
        "embeddings = model.encode(sentences, convert_to_tensor=True)\n",
        "\n",
        "print(\"Dataset hazƒ±rdƒ±r, embedding-l…ôr generasiya olundu.\")\n"
      ],
      "metadata": {
        "id": "WNv7tka23Fxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Universitetd…ô AI haqqƒ±nda t…ôdbir ba≈ü tutdu\"\n",
        "query_emb = model.encode(query, convert_to_tensor=True)\n",
        "\n",
        "print(\"Sorƒüu embedding-i hazƒ±rdƒ±r.\")\n"
      ],
      "metadata": {
        "id": "UYR5SnoJ3ID2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "scores = util.cos_sim(query_emb, embeddings)[0]\n",
        "\n",
        "\n",
        "for idx, score in enumerate(scores):\n",
        "    print(f\"{idx}. {sentences[idx]}  ---> Ox≈üarlƒ±q: {score:.4f}\")\n"
      ],
      "metadata": {
        "id": "aFfIe_JX3KBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "best_idx = torch.argmax(scores).item()\n",
        "\n",
        "print(\"\\nüìå ∆èn uyƒüun c√ºml…ô:\")\n",
        "print(sentences[best_idx])\n",
        "print(f\"Ox≈üarlƒ±q d…ôr…ôc…ôsi: {scores[best_idx]:.4f}\")\n"
      ],
      "metadata": {
        "id": "s3VadTGH3M_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sorted_results = torch.argsort(scores, descending=True)\n",
        "\n",
        "print(\"üìå ∆èn uyƒüun 3 n…ôtic…ô:\")\n",
        "for idx in sorted_results[:3]:\n",
        "    print(f\"- {sentences[idx]} (ox≈üarlƒ±q: {scores[idx]:.4f})\")\n"
      ],
      "metadata": {
        "id": "229atclf3O-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sentiment"
      ],
      "metadata": {
        "id": "q3m7nwC15DSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sentiment"
      ],
      "metadata": {
        "id": "Y4F7Ez2l5LZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sentiment"
      ],
      "metadata": {
        "id": "Wrt2dNzm5LlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers sentencepiece\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "\n",
        "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "print(\"Model y√ºkl…ôndi.\")"
      ],
      "metadata": {
        "id": "HKEa-uit5MPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "labels = {\n",
        "    0: \"√áox m…ônfi \",\n",
        "    1: \"M…ônfi \",\n",
        "    2: \"Neytral \",\n",
        "    3: \"M√ºsb…ôt \",\n",
        "    4: \"√áox m√ºsb…ôt\"\n",
        "}\n",
        "\n",
        "def sentiment(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    outputs = model(**inputs)\n",
        "    probabilities = torch.softmax(outputs.logits, dim=1)[0].detach().numpy()\n",
        "    label_id = np.argmax(probabilities)\n",
        "    return labels[label_id], float(probabilities[label_id])\n"
      ],
      "metadata": {
        "id": "GtLoz-1p63jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Bu g√ºn d…ôrs √ßox maraqlƒ± ke√ßdi, √∂z√ºm√º …ôla hiss edir…ôm!\"\n",
        "result, prob = sentiment(text)\n",
        "\n",
        "print(f\"M…ôtn: {text}\")\n",
        "print(f\"Sentiment: {result} (ehtimal: {prob:.4f})\")\n"
      ],
      "metadata": {
        "id": "9RYD-UYS65OY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"Universitetd…ô xidm…ôt s…ôviyy…ôsi √ßox z…ôif idi.\",\n",
        "    \"Bu layih…ô m…ôni √ßox h…ôy…ôcanlandƒ±rƒ±r!\",\n",
        "    \"T…ôlim normal ke√ßdi.\",\n",
        "    \"Sistemd…ô xeyli probleml…ôr var idi, narazƒ± qaldƒ±m.\",\n",
        "    \"Yeni platforma g√∂zl…ôdiyimd…ôn daha yax≈üƒ± i≈ül…ôyir.\"\n",
        "]\n",
        "\n",
        "for s in sentences:\n",
        "    label, prob = sentiment(s)\n",
        "    print(f\"{s} ---> {label} (ehtimal: {prob:.4f})\")\n"
      ],
      "metadata": {
        "id": "mOVqpfc-66ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "probs = []\n",
        "for s in sentences:\n",
        "    inputs = tokenizer(s, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    outputs = model(**inputs)\n",
        "    p = torch.softmax(outputs.logits, dim=1)[0].detach().numpy()\n",
        "    probs.append(p)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "sns.heatmap(probs, annot=True, cmap=\"Blues\",\n",
        "            yticklabels=sentences,\n",
        "            xticklabels=list(labels.values()))\n",
        "plt.title(\"Az…ôrbaycan c√ºml…ôl…ôri √ºzr…ô Sentiment heatmap\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ucjwga0p68jY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "def sentiment_grouped(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    outputs = model(**inputs)\n",
        "    probs = torch.softmax(outputs.logits, dim=1)[0].detach().numpy()\n",
        "\n",
        "\n",
        "    stars = np.argmax(probs) + 1\n",
        "\n",
        "    if stars in [1, 2]:\n",
        "        label = \"M…ônfi\"\n",
        "    elif stars == 3:\n",
        "        label = \"Neytral\"\n",
        "    else:\n",
        "        label = \"M√ºsb…ôt\"\n",
        "\n",
        "    return stars, label, probs\n",
        "sentences = [\n",
        "    \"Universitetd…ô xidm…ôt s…ôviyy…ôsi √ßox z…ôif idi.\",\n",
        "    \"Bu layih…ô m…ôni √ßox h…ôy…ôcanlandƒ±rƒ±r!\",\n",
        "    \"T…ôlim normal ke√ßdi.\",\n",
        "    \"Sistemd…ô xeyli probleml…ôr var idi, narazƒ± qaldƒ±m.\",\n",
        "    \"Yeni platforma g√∂zl…ôdiyimd…ôn daha yax≈üƒ± i≈ül…ôyir.\"\n",
        "]\n",
        "\n",
        "for s in sentences:\n",
        "    stars, label, probs = sentiment_grouped(s)\n",
        "    print(f\"{s}  ‚Üí  {label} ({stars}‚òÖ)\")\n"
      ],
      "metadata": {
        "id": "5BEO8Q6K8Ai4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "model_name = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "labels = [\"M…ônfi\", \"Neytral\", \"M√ºsb…ôt\"]\n",
        "\n",
        "def sentiment_xlm(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
        "    outputs = model(**inputs)\n",
        "    probs = torch.softmax(outputs.logits, dim=1)[0].detach().numpy()\n",
        "    label_id = np.argmax(probs)\n",
        "    return labels[label_id], probs[label_id], probs\n",
        "sentences = [\n",
        "    \"Universitetd…ô xidm…ôt s…ôviyy…ôsi √ßox z…ôif idi.\",\n",
        "    \"Bu layih…ô m…ôni √ßox h…ôy…ôcanlandƒ±rƒ±r!\",\n",
        "    \"T…ôlim normal ke√ßdi.\",\n",
        "    \"Sistemd…ô xeyli probleml…ôr var idi, narazƒ± qaldƒ±m.\",\n",
        "    \"Yeni platforma g√∂zl…ôdiyimd…ôn daha yax≈üƒ± i≈ül…ôyir.\"\n",
        "]\n",
        "\n",
        "for s in sentences:\n",
        "    label, prob, raw = sentiment_xlm(s)\n",
        "    print(f\"{s}  ‚Üí  {label} (ehtimal: {prob:.3f})\")\n"
      ],
      "metadata": {
        "id": "zKlUrlxP8CI9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}